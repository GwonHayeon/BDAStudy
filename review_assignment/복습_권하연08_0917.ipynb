{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ef2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25afa824",
   "metadata": {},
   "source": [
    "### 교차검증의 종류\n",
    "- 훈련용과 검증용으로 교차하여 모델학습을 시키는 방법으로 과적합을 줄이는데 사용한다\n",
    "- KFold, SKFold(계층적 KFold) 이용\n",
    "- cross_val_score, cross_validate를 이용하면 회귀에는 Kfold, 분류에는 SKFold가 사용된다\n",
    "- cross_val_score(사용할 모델, x값, y값, scoring(평가할 스코어링 방법), cv 몇번 교차 검증할 것인가? n_jobs(cpu사용에 대한 지정 -1), verbose(진행상황보기), 교차 검증 되는 상황 체크, fit_params 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570f0785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.000000         0.0    0.966667          1.0\n",
       "1  0.000000         0.0    0.966667          1.0\n",
       "2  0.001312         0.0    0.900000          1.0\n",
       "3  0.000000         0.0    0.966667          1.0\n",
       "4  0.007997         0.0    1.000000          1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=111)\n",
    "crs = cross_validate(dt_clf, data, label, scoring='accuracy', cv=5, return_train_score=True)\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04dacdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "#교차검증 진행\n",
    "scores=cross_val_score(dt_clf, data,label, scoring='accuracy',cv=5)\n",
    "print(np.round(np.mean(scores),3)) #교차검증의 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ae4001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65041256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 115, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1391, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 115, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1391, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 115, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1391, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 115, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1391, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 115, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 282, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1954, in precision_score\n",
      "    p, _, _, _ = precision_recall_fscore_support(\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1573, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"C:\\Users\\lockd\\anaconda3\\envs\\pyTest\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1391, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#### Confusion matrix\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "scores = cross_val_score(dt_clf, data, label, scoring='precision', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa942480",
   "metadata": {},
   "source": [
    "  - 흔히 말하는 계산방식 정확도, 정밀도, 재현율, f1스코어, auc, roc 커브 등등 0,1 이진 분류에만 디폴트로 적용된 것\n",
    "  - 이진분류는 문제없이 값들이 나옴\n",
    "- 다중분류는 값을 평가하는 방식이 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0331e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dt_clf, data, label, scoring='precision_micro', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27df6f9",
   "metadata": {},
   "source": [
    "### scoring 종류\n",
    "- **Classification**\n",
    "  - accuracy\n",
    "  - f1\n",
    "  - average_precision\n",
    "  - precision etc\n",
    "  - recall etc\n",
    "  - roc etc\n",
    "- **Clutstering**\n",
    "  - mutual_info_score\n",
    "  - rand_score\n",
    "  - measure_score\n",
    "- **Regression**\n",
    "  - absolute_error\n",
    "  - squared_error\n",
    "  - poisson_deviance\n",
    "  - gamma_deviance\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74cff8",
   "metadata": {},
   "source": [
    "## 다중분류 진행 시 정확도 외 다른 평가지표에 대한 가중치 설정 방법\n",
    "- macro : 모든 예측 결과에 대해서 평균을 내어서 값을 계산하는 방법\n",
    "- micro : 각각의 정답에 대한 개수를 가지고 나눠서 평균값을 구한다\n",
    "- weighted : 가중 평균값을 구한다. 가중치를 주고 싶은 것에 줄 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9584048a",
   "metadata": {},
   "source": [
    "- TP : 참긍정. 긍정인것 중 긍정이라고 예측\n",
    "- FP : 거짓긍정. 부정인것 중 긍정이라고 예측\n",
    "- FN : 거짓부정. 긍정인것 중 부정이라고 예측\n",
    "- TN : 참부정. 부정인것 중 부정이라고 예측 \n",
    "\n",
    "- **정확도**(예측이 현실에 부합할 확률) = $\\frac{TP+TN}{TP+TN+FP+FN}$\n",
    "- **정밀도**(긍정예측 중에 실제 긍정일 확률) = $\\frac{TP}{TP+FP}$\n",
    "- **민감도**(=재현율. 실제 긍정중 긍정이라고 예측할 확률) = $\\frac{TP}{TP+FN}$\n",
    "- **특이도**(실제로 부정일 때 예측도 부정일 확률) = $\\frac{TN}{TN+FP}$\n",
    "- **F1값** = $\\frac{2*Precicion*Recall}{Precision+Recall}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d28cb09",
   "metadata": {},
   "source": [
    "<img src=\"https://www.mariakhalusova.com/images/metrics/micro-macro-table.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aacc3d6",
   "metadata": {},
   "source": [
    "$precision = \\frac{TP_{total}}{TP_{total}+FP_{total}}$\n",
    "\n",
    "$Macro-Precision = \\frac{1}{3}(Precision_{bird}+Precision_{cat}+Precision_{dog})\n",
    "= \\frac{1}{3}(1+0.8+0.667)$\n",
    "\n",
    "$Micro-Precision = \\frac{TP_{total}}{TP_{total}+FP_{total}}=\\frac{7}{7+2}$\n",
    "\n",
    "$weighted-Precision = \\frac {Precision_{bird}*N_{bird}+Precision_{cat}*N_{cat}+Precision_{dog}*N_{dog}}{Total number of samples} = \\frac {1*2+0.8*4+0.667*3}{9}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2274669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96666667, 0.96666667, 0.9       , 0.96666667, 1.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a6a70",
   "metadata": {},
   "source": [
    "## leaveOneOut 교차검증\n",
    "-  단 하나의 관측값을 validation set으로 사용하고 나머지 n-1개 관측값은 train set으로 사용\n",
    "\n",
    "## Group 교차검증\n",
    "- 그룹핑은 그룹핑 데이터를 가지고 교차검증할 때 더 좋은 성능을 보여줄 수 있다\n",
    "- 단순하게 교차검증을 cross 하는 게 아니라\n",
    "- 데이터의 특성을 보고 내가 분석 할 것이 어떤 클래스별의 수치를 비교하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1274c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "df_tt=df[['pclass','fare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2af9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "scores = cross_val_score(dt_clf, df_tt, df['survived'],scoring='accuracy',cv=loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8497b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "0.6745230078563412\n"
     ]
    }
   ],
   "source": [
    "print(len(scores))\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e150cd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************사용한 알고리즘 DT  *****************\n",
      "accuracy\n",
      "--\n",
      "[0.67777778 0.61797753 0.64044944 0.66292135 0.6741573  0.71910112\n",
      " 0.61797753 0.78651685 0.71910112 0.75280899]\n",
      "precision\n",
      "--\n",
      "[0.63636364 0.5        0.54545455 0.59090909 0.6        0.63636364\n",
      " 0.5        0.74193548 0.65517241 0.76      ]\n",
      "recall\n",
      "--\n",
      "[0.4        0.35294118 0.35294118 0.38235294 0.44117647 0.61764706\n",
      " 0.32352941 0.67647059 0.55882353 0.54285714]\n",
      "f1\n",
      "--\n",
      "[0.49122807 0.4137931  0.42857143 0.46428571 0.50847458 0.62686567\n",
      " 0.39285714 0.70769231 0.6031746  0.63333333]\n",
      "*************사용한 알고리즘 RF  *****************\n",
      "accuracy\n",
      "--\n",
      "[0.7        0.64044944 0.6741573  0.6741573  0.69662921 0.70786517\n",
      " 0.68539326 0.78651685 0.71910112 0.7752809 ]\n",
      "precision\n",
      "--\n",
      "[0.65384615 0.48148148 0.60714286 0.59259259 0.62962963 0.62857143\n",
      " 0.66666667 0.6969697  0.67741935 0.74074074]\n",
      "recall\n",
      "--\n",
      "[0.45714286 0.35294118 0.47058824 0.44117647 0.5        0.67647059\n",
      " 0.38235294 0.70588235 0.61764706 0.62857143]\n",
      "f1\n",
      "--\n",
      "[0.56666667 0.42622951 0.50847458 0.5625     0.53333333 0.65714286\n",
      " 0.45614035 0.70769231 0.63636364 0.64516129]\n",
      "*************사용한 알고리즘 LR  *****************\n",
      "accuracy\n",
      "--\n",
      "[0.58888889 0.61797753 0.68539326 0.66292135 0.69662921 0.65168539\n",
      " 0.70786517 0.73033708 0.70786517 0.74157303]\n",
      "precision\n",
      "--\n",
      "[0.44444444 0.5        0.66666667 0.56666667 0.70588235 0.55555556\n",
      " 0.66666667 0.72727273 0.66666667 0.8       ]\n",
      "recall\n",
      "--\n",
      "[0.22857143 0.23529412 0.35294118 0.5        0.35294118 0.44117647\n",
      " 0.47058824 0.47058824 0.47058824 0.45714286]\n",
      "f1\n",
      "--\n",
      "[0.30188679 0.32       0.46153846 0.53125    0.47058824 0.49180328\n",
      " 0.55172414 0.57142857 0.55172414 0.58181818]\n"
     ]
    }
   ],
   "source": [
    "## cross val 응용하기\n",
    "model = [DecisionTreeClassifier(),RandomForestClassifier(),LogisticRegression()]\n",
    "name = ['DT','RF',\"LR\"]\n",
    "\n",
    "for model,name in zip(model, name):\n",
    "    print('*************사용한 알고리즘', name, ' *****************')\n",
    "    for score in ['accuracy','precision','recall','f1']:\n",
    "                  print(score)\n",
    "                  print(\"--\")\n",
    "                  print(cross_val_score(model, df_tt, df['survived'], scoring=score, cv=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79566dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
